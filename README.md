# Job Market Demand Forecaster

A complete ML-powered application that forecasts weekly job postings volume using LSTM neural networks. Built with PyTorch for training, FastAPI for serving, and React for visualization.

## ğŸ“‹ Table of Contents

- [Architecture](#architecture)
- [Features](#features)
- [Quick Start (Offline)](#quick-start-offline)
- [Setup Instructions](#setup-instructions)
- [Usage](#usage)
- [Data Leakage Prevention](#data-leakage-prevention)
- [Project Structure](#project-structure)
- [API Documentation](#api-documentation)
- [Testing](#testing)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend (React)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ForecastChart.jsx  â”‚  App.jsx  â”‚  api.js           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â†• HTTP/REST                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Backend API (FastAPI)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  main.py  â”‚  forecast.py  â”‚  data_store.py          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â†•                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Load Model Artifacts (model.pt, scaler.pkl)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ML Training Pipeline (PyTorch)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  train.py â†’ models.py â†’ datasets.py â†’ export.py     â”‚   â”‚
â”‚  â”‚  baselines.py â†’ evaluate.py                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â†•                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Processed CSV â†’ Sliding Windows â†’ LSTM Training    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Data Pipeline                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  fetch_usajobs.py â†’ data/raw/                       â”‚   â”‚
â”‚  â”‚  process.py â†’ data/processed/                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

- **LSTM-based Forecasting**: Deep learning model for time series prediction
- **Baseline Comparisons**: Naive, Moving Average, and optional ARIMA baselines
- **RESTful API**: FastAPI backend with automatic documentation
- **Interactive Dashboard**: React frontend with Recharts visualization
- **Data Leakage Prevention**: Proper train/val/test splits with scaler fitting on train only
- **Deterministic Runs**: Reproducible training with fixed seeds
- **Offline Capable**: Sample data included for testing without API access

## ğŸš€ Quick Start (Offline)

The repository includes sample processed data and can work offline. To get started quickly:

### 1. Backend Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
cd backend
pip install -r requirements.txt

# Install ML dependencies (if not included)
pip install torch scikit-learn matplotlib pandas numpy

# Start backend server
cd ..
uvicorn backend.app.main:app --reload
```

The API will be available at `http://localhost:8000`

### 2. Frontend Setup

```bash
# Install dependencies
cd frontend
npm install

# Start dev server
npm run dev
```

The frontend will be available at `http://localhost:3000`

### 3. Train a Model (Optional)

If you want to train a model from the sample data:

```bash
python ml/train.py \
  --csv data/processed/software_engineer_new_york,ny.csv \
  --role "Software Engineer" \
  --location "New York, NY" \
  --window 12 \
  --epochs 50
```

This will:
- Train an LSTM model
- Evaluate against baselines
- Generate forecast plots
- Export model artifacts to `backend/app/artifacts/`

### 4. View Results

- Open `http://localhost:3000` in your browser
- Select a role and location from the dropdowns
- Click "Generate Forecast" to see predictions

## ğŸ“¦ Setup Instructions

### Prerequisites

- Python 3.8+
- Node.js 16+ and npm
- (Optional) USAJOBS API credentials for live data fetching

### Backend Setup

1. **Create virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate
   ```

2. **Install Python dependencies:**
   ```bash
   pip install -r backend/requirements.txt
   pip install torch scikit-learn matplotlib statsmodels  # ML dependencies
   ```

3. **Set environment variables (optional, for USAJOBS API):**
   ```bash
   export USAJOBS_API_KEY="your-api-key"
   export USAJOBS_USER_AGENT="your-email@example.com"
   ```

### Frontend Setup

1. **Install dependencies:**
   ```bash
   cd frontend
   npm install
   ```

2. **Configure API endpoint (optional):**
   Create `frontend/.env.local`:
   ```
   VITE_API_BASE=http://localhost:8000
   ```

## ğŸ“Š Usage

### Data Ingestion

#### Option 1: Use Sample Data (Offline)

Sample processed CSV files are included in `data/processed/`:
- `software_engineer_new_york,ny.csv`
- `data_scientist_san_francisco,ca.csv`
- `product_manager_remote.csv`

#### Option 2: Fetch from USAJOBS API

1. **Fetch raw data:**
   ```bash
   python data/fetch_usajobs.py \
     --keyword "Software Engineer" \
     --location "New York, NY" \
     --date-from "2022-01-01" \
     --date-to "2024-12-31" \
     --output data/raw/software_engineer_nyc.json
   ```

2. **Process to weekly aggregates:**
   ```bash
   python data/process.py \
     --input data/raw/software_engineer_nyc.json \
     --role "Software Engineer" \
     --location "New York, NY" \
     --output data/processed/software_engineer_new_york,ny.csv
   ```

### Model Training

Train an LSTM model:

```bash
python ml/train.py \
  --csv data/processed/software_engineer_new_york,ny.csv \
  --role "Software Engineer" \
  --location "New York, NY" \
  --window 12 \
  --hidden-size 64 \
  --num-layers 2 \
  --epochs 50 \
  --batch-size 32 \
  --learning-rate 0.001
```

**Arguments:**
- `--csv`: Path to processed CSV file
- `--role`: Job role name
- `--location`: Location name
- `--window`: Window size for LSTM (default: 12)
- `--hidden-size`: LSTM hidden units (default: 64)
- `--num-layers`: Number of LSTM layers (default: 2)
- `--epochs`: Training epochs (default: 50)
- `--batch-size`: Batch size (default: 32)
- `--learning-rate`: Learning rate (default: 0.001)

**Outputs:**
- Model artifacts in `backend/app/artifacts/<role_slug>_<location_slug>/`
- Metrics in `reports/metrics.json`
- Forecast plot in `reports/forecast_plot.png`

### Running the Application

1. **Start backend:**
   ```bash
   uvicorn backend.app.main:app --reload
   ```

2. **Start frontend:**
   ```bash
   cd frontend
   npm run dev
   ```

3. **Access dashboard:**
   Open `http://localhost:3000`

## ğŸ”’ Data Leakage Prevention

The implementation follows strict practices to prevent data leakage:

### 1. **Chronological Splitting**
- Train/val/test splits are done **chronologically** (no shuffling)
- This preserves the temporal nature of time series data

### 2. **Scaler Fitting**
- Scaler is fitted **only on training data**
- Same scaler is then applied to validation and test sets
- This prevents future information from leaking into training

### 3. **Window-Based Sequences**
- Each training sample uses only past data (no future lookahead)
- Sliding windows ensure no overlap between train/val/test sequences

### 4. **No Information Leakage in Training**
- Model never sees test data during training
- Early stopping uses only validation loss
- Metrics are computed separately for each split

**Implementation details:**

```python
# In ml/datasets.py
def prepare_datasets(train_df, val_df, test_df, ...):
    # Fit scaler ONLY on training data
    scaler.fit(train_values)
    
    # Apply same scaler to all splits
    train_scaled = scaler.transform(train_values)
    val_scaled = scaler.transform(val_values)  # Using train's parameters
    test_scaled = scaler.transform(test_values)  # Using train's parameters
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Cached USAJOBS API responses
â”‚   â”œâ”€â”€ processed/              # Weekly aggregated CSV files
â”‚   â”œâ”€â”€ fetch_usajobs.py        # API fetching script
â”‚   â””â”€â”€ process.py              # Data processing script
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ train.py                # End-to-end training script
â”‚   â”œâ”€â”€ models.py               # LSTM model definition
â”‚   â”œâ”€â”€ datasets.py             # Time series dataset utilities
â”‚   â”œâ”€â”€ baselines.py            # Baseline models
â”‚   â”œâ”€â”€ evaluate.py             # Metrics and visualization
â”‚   â””â”€â”€ export.py               # Model artifact export
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPI application
â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic models
â”‚   â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ forecast.py     # Forecast service
â”‚   â”‚   â”‚   â””â”€â”€ data_store.py   # Data access service
â”‚   â”‚   â””â”€â”€ artifacts/          # Trained model artifacts
â”‚   â””â”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx             # Main React component
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ ForecastChart.jsx
â”‚   â”‚   â”œâ”€â”€ api.js              # API client
â”‚   â”‚   â””â”€â”€ App.css
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ reports/                    # Training metrics and plots
â”œâ”€â”€ tests/                      # Unit tests
â””â”€â”€ README.md
```

## ğŸ“¡ API Documentation

### Endpoints

#### `GET /health`
Health check endpoint.

**Response:**
```json
{
  "ok": true
}
```

#### `GET /series`
Get historical time series data.

**Query Parameters:**
- `role` (required): Job role name
- `location` (required): Location name
- `max_weeks` (optional): Maximum weeks to return (default: 104)

**Response:**
```json
{
  "role": "Software Engineer",
  "location": "New York, NY",
  "series": [
    {
      "week_start": "2022-01-03",
      "value": 45.0
    },
    ...
  ]
}
```

#### `GET /forecast`
Generate forecast for a role/location.

**Query Parameters:**
- `role` (required): Job role name
- `location` (required): Location name
- `horizon` (optional): Forecast horizon in weeks (1-52, default: 8)

**Response:**
```json
{
  "role": "Software Engineer",
  "location": "New York, NY",
  "history": [
    {
      "week_start": "2022-01-03",
      "value": 45.0
    },
    ...
  ],
  "forecast": [
    {
      "week_start": "2024-12-30",
      "value": 279.0
    },
    ...
  ],
  "model": {
    "type": "lstm",
    "window": 12,
    "trained_on": "2024-01-15T10:30:00"
  }
}
```

**Interactive API docs:** Visit `http://localhost:8000/docs` when the server is running.

## ğŸ§ª Testing

Run tests:

```bash
# Install test dependencies
pip install pytest

# Run all tests
pytest tests/

# Run specific test file
pytest tests/test_datasets.py -v

# Run with coverage
pytest --cov=ml --cov=backend tests/
```

## ğŸ“ Notes

- **USAJOBS API**: Requires free API key from [USAJOBS](https://developer.usajobs.gov/)
- **Deterministic Training**: Set `torch.manual_seed()` for reproducibility
- **Model Artifacts**: Models are saved with metadata including training date range and metrics
- **Recursive Forecasting**: Multi-step forecasts use recursive prediction (1-step model applied repeatedly)

## ğŸ¤ Contributing

This is a complete, runnable project. To extend:

1. Add new baseline models in `ml/baselines.py`
2. Modify LSTM architecture in `ml/models.py`
3. Add new API endpoints in `backend/app/main.py`
4. Extend frontend components in `frontend/src/`

## ğŸ“„ License

This project is provided as-is for educational and demonstration purposes.
